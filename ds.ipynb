{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pre_processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "stopwords = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_punctuation(text):\n",
    "    cleaned_text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return cleaned_text\n",
    "\n",
    "# پنج تا کار لوور لمتایز یونیک استاپ ورد نباشه پانکچوشن نباشه\n",
    "def tokenize_text(sentence):\n",
    "    sentence = remove_punctuation(sentence)\n",
    "    tokens = word_tokenize(sentence.lower())  # Tokenize and convert to lowercase\n",
    "    tokens = set(lemmatizer.lemmatize(token) for token in tokens if token not in stopwords)\n",
    "    return list(tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________\n",
    "for smaller : 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [00:00<00:00, 94.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 94.21it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm import tqdm\n",
    "\n",
    "data_folder = 'data'\n",
    "data_list = []\n",
    "\n",
    "# Set the maximum number of files to process\n",
    "max_files = 20\n",
    "\n",
    "unique_tokens_in_all = set()\n",
    "\n",
    "for i in tqdm(range(max_files)):\n",
    "    filename = f\"document_{i}.txt\"\n",
    "    file_path = os.path.join(data_folder, filename)\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    tokens = tokenize_text(content)\n",
    "\n",
    "    unique_tokens_in_all |= set(tokens)  # Union update with the tokens of the current document\n",
    "\n",
    "    data_list.append({'Filename': filename, 'unique Tokens of document': tokens, 'Content': content})\n",
    "\n",
    "df = pd.DataFrame(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>unique Tokens of document</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>document_0.txt</td>\n",
       "      <td>[likelihood, work, applied, banknote, surprisi...</td>\n",
       "      <td>Since 2007, the RBA's outstanding reputation h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>document_1.txt</td>\n",
       "      <td>[jimmy, republican, running, ever, think, 1911...</td>\n",
       "      <td>In his younger years, Ronald Reagan was a memb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>document_2.txt</td>\n",
       "      <td>[week, sight, consisting, area, submergent, fo...</td>\n",
       "      <td>Sydney, New South Wales, Australia is located ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>document_3.txt</td>\n",
       "      <td>[2689, painti, end, one, foot, let, 180, avail...</td>\n",
       "      <td>In regards to tile installation costs, consume...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>document_4.txt</td>\n",
       "      <td>[necessary, important, primary, one, intention...</td>\n",
       "      <td>Conclusions: In adult body CT, dose to an orga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>document_5.txt</td>\n",
       "      <td>[webmd, vertebrate, upper, find, becoming, rig...</td>\n",
       "      <td>Get the Latest health and medical information ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>document_6.txt</td>\n",
       "      <td>[subject, prosecution, depend, find, 100000, c...</td>\n",
       "      <td>“there will be post-filing costs once the Pate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>document_7.txt</td>\n",
       "      <td>[low, identification, gastrointestinal, primar...</td>\n",
       "      <td>Background. Metabolic acidosis is a clinical d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>document_8.txt</td>\n",
       "      <td>[three, world, nineteen, work, subject, surviv...</td>\n",
       "      <td>Three well-known Greek tragedy playwrights of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>document_9.txt</td>\n",
       "      <td>[growth, juniper, long, trapping, one, leaf, p...</td>\n",
       "      <td>All extant conifers are woody plants with seco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>document_10.txt</td>\n",
       "      <td>[relevance, certain, one, almost, mitosis, ha,...</td>\n",
       "      <td>For an example, a human gamete contains only 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>document_11.txt</td>\n",
       "      <td>[world, work, seuss, think, breslin, pen, sept...</td>\n",
       "      <td>For the TV special, see The Cat in the Hat (TV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>document_12.txt</td>\n",
       "      <td>[preheat, 180, shallow, 45, drizzle, 9x13, can...</td>\n",
       "      <td>Bake the chicken. Put the chicken in the oven ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>document_13.txt</td>\n",
       "      <td>[area, installed, radiant, 320, foot, interest...</td>\n",
       "      <td>Back to Top How much should a typical radiant ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>document_14.txt</td>\n",
       "      <td>[century, available, second, tripoint, cluster...</td>\n",
       "      <td>Pumice is a light-colored, extremely porous ig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>document_15.txt</td>\n",
       "      <td>[three, area, work, installed, 30ft, configura...</td>\n",
       "      <td>Basic concrete slab cost. I'll base my price o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>document_16.txt</td>\n",
       "      <td>[three, long, certain, one, orangetail, aquari...</td>\n",
       "      <td>Known by multiple common names, such as humbug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>document_17.txt</td>\n",
       "      <td>[general, origin, newspaper, think, cliche, sp...</td>\n",
       "      <td>The first reference to the phrase, '...it is w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>document_18.txt</td>\n",
       "      <td>[low, area, work, running, garment, long, end,...</td>\n",
       "      <td>Today's oilskins (or oilies) typically come in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>document_19.txt</td>\n",
       "      <td>[week, long, mild, shot, airspace, also, term,...</td>\n",
       "      <td>Measles is a highly contagious virus that live...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Filename                          unique Tokens of document  \\\n",
       "0    document_0.txt  [likelihood, work, applied, banknote, surprisi...   \n",
       "1    document_1.txt  [jimmy, republican, running, ever, think, 1911...   \n",
       "2    document_2.txt  [week, sight, consisting, area, submergent, fo...   \n",
       "3    document_3.txt  [2689, painti, end, one, foot, let, 180, avail...   \n",
       "4    document_4.txt  [necessary, important, primary, one, intention...   \n",
       "5    document_5.txt  [webmd, vertebrate, upper, find, becoming, rig...   \n",
       "6    document_6.txt  [subject, prosecution, depend, find, 100000, c...   \n",
       "7    document_7.txt  [low, identification, gastrointestinal, primar...   \n",
       "8    document_8.txt  [three, world, nineteen, work, subject, surviv...   \n",
       "9    document_9.txt  [growth, juniper, long, trapping, one, leaf, p...   \n",
       "10  document_10.txt  [relevance, certain, one, almost, mitosis, ha,...   \n",
       "11  document_11.txt  [world, work, seuss, think, breslin, pen, sept...   \n",
       "12  document_12.txt  [preheat, 180, shallow, 45, drizzle, 9x13, can...   \n",
       "13  document_13.txt  [area, installed, radiant, 320, foot, interest...   \n",
       "14  document_14.txt  [century, available, second, tripoint, cluster...   \n",
       "15  document_15.txt  [three, area, work, installed, 30ft, configura...   \n",
       "16  document_16.txt  [three, long, certain, one, orangetail, aquari...   \n",
       "17  document_17.txt  [general, origin, newspaper, think, cliche, sp...   \n",
       "18  document_18.txt  [low, area, work, running, garment, long, end,...   \n",
       "19  document_19.txt  [week, long, mild, shot, airspace, also, term,...   \n",
       "\n",
       "                                              Content  \n",
       "0   Since 2007, the RBA's outstanding reputation h...  \n",
       "1   In his younger years, Ronald Reagan was a memb...  \n",
       "2   Sydney, New South Wales, Australia is located ...  \n",
       "3   In regards to tile installation costs, consume...  \n",
       "4   Conclusions: In adult body CT, dose to an orga...  \n",
       "5   Get the Latest health and medical information ...  \n",
       "6   “there will be post-filing costs once the Pate...  \n",
       "7   Background. Metabolic acidosis is a clinical d...  \n",
       "8   Three well-known Greek tragedy playwrights of ...  \n",
       "9   All extant conifers are woody plants with seco...  \n",
       "10  For an example, a human gamete contains only 2...  \n",
       "11  For the TV special, see The Cat in the Hat (TV...  \n",
       "12  Bake the chicken. Put the chicken in the oven ...  \n",
       "13  Back to Top How much should a typical radiant ...  \n",
       "14  Pumice is a light-colored, extremely porous ig...  \n",
       "15  Basic concrete slab cost. I'll base my price o...  \n",
       "16  Known by multiple common names, such as humbug...  \n",
       "17  The first reference to the phrase, '...it is w...  \n",
       "18  Today's oilskins (or oilies) typically come in...  \n",
       "19  Measles is a highly contagious virus that live...  "
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2464\n",
      "['0', '05', '09', '1', '10', '100', '10000', '100000', '10000000000', '11', '1109', '12', '120', '1200', '12000', '12145', '1215', '125', '130', '1380', '14', '140', '1400', '15', '150', '1500', '15000', '150400', '160', '165', '17771779', '1788', '180', '1883', '19', '1904', '19041991', '1911', '19112004', '1919', '1927', '1935', '1937', '194', '1943', '1948', '1949', '1950', '1955', '1956', '1957', '1959', '1960', '1960s', '1962', '1966', '1967', '1970', '1970s', '1975', '1980', '1981', '1983', '1984', '1989', '1991', '199193', '1km', '1st', '2', '20', '200', '2000', '20000', '20000000', '2001', '2003', '2004', '2007', '2014', '2015', '2025', '20th', '22', '220', '2200', '22000000', '225', '22552', '23', '24', '245', '2459', '25', '2500', '25000', '2689', '29', '3', '30', '300', '3000', '30ft', '32', '320', '344', '349', '35', '350', '3500', '35x45km', '36', '375', '375f', '38', '380', '39', '3stripe', '4', '40', '400', '4000', '400f', '4045', '406', '40th', '45', '450000700000', '46', '464', '4689', '47', '47474', '484407', '49', '496', '499', '4km', '5', '50', '5000', '51', '517', '525', '538', '5450', '550', '5th', '6', '60120', '612', '616', '63', '636', '690', '699', '6th', '7', '70', '7000', '735', '745', '75', '7500', '789', '8', '80', '8000', '80100', '8100', '900', '900022500', '94', '953', '9x13', '________', 'a101', 'abnormal', 'abovethen', 'abrasive', 'abscess', 'absence', 'abundant', 'accept', 'access', 'account', 'accountability', 'accumulation', 'acid', 'acidbase', 'acidic', 'acidity', 'acidosis', 'acidosismetabolic', 'across', 'act', 'action', 'active', 'activity', 'actor', 'actual', 'actually', 'adage', 'adaptable', 'adapts', 'add', 'added', 'addition', 'additional', 'addressing', 'adirondack', 'adjective', 'administered', 'adopted', 'adorable', 'adorned', 'adult', 'adult6', 'aerosol', 'aeschylus', 'affect', 'affected', 'age', 'aggregate', 'aggressive', 'ago', 'air', 'airbreathing', 'airfilled', 'airport', 'airspace', 'alcohol', 'algae', 'alkaline', 'alkalosis', 'allowed', 'allpurpose', 'almost', 'along', 'alphabetical', 'also', 'alternating', 'although', 'aluminum', 'alveolus', 'always', 'america', 'american', 'among', 'amount', 'amphiprion', 'analysis', 'anatomical', 'ancestral', 'ancient', 'andesite', 'andesitic', 'anemonefishes', 'animal', 'animated', 'annual', 'another', 'answer', 'anthropomorphic', 'antigone', 'anything', 'anywhere', 'aorta', 'apart', 'appear', 'appearance', 'appears', 'application', 'applied', 'applying', 'appropriate', 'approval', 'approved', 'approx', 'approximate', 'approximately', 'april', 'aquarists', 'aquarium', 'area', 'arent', 'arillate', 'arising', 'aristophanes', 'arm', 'around', 'arrange', 'art', 'arterial', 'artery', 'article', 'aruanus', 'ash', 'ask', 'asset', 'associated', 'assortment', 'assumption', 'athens', 'atomizer', 'atrium', 'attend', 'attitude', 'attorney', 'attraction', 'attributed', 'audio', 'australia', 'australian', 'authentication', 'author', 'authoring', 'authority', 'automatically', 'available', 'average', 'award', 'awarded', 'away', 'aww', 'b', 'back', 'backbone', 'backed', 'background', 'backward', 'bake', 'baking', 'balance', 'band', 'bank', 'banking', 'banknote', 'bar', 'barrier', 'basalt', 'base', 'based', 'baseline', 'basic', 'basin', 'bathroom', 'bay', 'bc', 'bce', 'beach', 'beam', 'bear', 'bearing', 'beat', 'beautiful', 'became', 'become', 'becoming', 'bed', 'beeswax', 'began', 'beginner', 'benchmark', 'best', 'bestseller', 'better', 'beyond', 'bicarbonate', 'big', 'bike', 'bill', 'billion', 'bit', 'black', 'blasted', 'blindness', 'blocked', 'blood', 'blow', 'blue', 'body', 'boiled', 'boiler', 'bold', 'bondi', 'bone', 'book', 'bordered', 'born', 'bottom', 'bow', 'brackish', 'brain', 'branch', 'breakdown', 'breakout', 'breath', 'breathe', 'breathing', 'breeding', 'breslin', 'brett', 'bribing', 'bright', 'brightly', 'bringing', 'broad', 'bronchiole', 'bronchitis', 'bronchus', 'brought', 'brown', 'budget', 'build', 'building', 'buildup', 'bundok', 'business', 'buy', 'c', 'cabusilan', 'cafe', 'cage', 'calculator', 'caldera', 'california', 'called', 'came', 'campaigned', 'cancer', 'candidate', 'canola', 'cant', 'capable', 'capital', 'car', 'carbohydrate', 'carbon', 'carboniferous', 'cardiac', 'care', 'career', 'carried', 'carry', 'carter', 'cartoonist', 'cartwright', 'carved', 'case', 'casual', 'cat', 'categorized', 'categorylocal', 'categorysuburbs', 'caudal', 'cause', 'caused', 'causing', 'cavity', 'cbd', 'ccf', 'cedar', 'ceiling', 'celebrated', 'celebrity', 'cell', 'cemented', 'census', 'center', 'central', 'centre', 'century', 'ceramic', 'certain', 'cerulean', 'challenge', 'challenger', 'chamber', 'change', 'changed', 'character', 'characteristic', 'characterized', 'charge', 'cheap', 'check', 'chemical', 'chest', 'chicken', 'chickenpox', 'chief', 'child', 'childrens', 'choice', 'choosing', 'choral', 'christmas', 'chromatid', 'chromisthese', 'chromosomal', 'chromosome', 'chronic', 'circus', 'city', 'class', 'classic', 'classification', 'classified', 'clean', 'cleanse', 'clear', 'clearomizer', 'clever', 'cliche', 'click', 'clinical', 'clinton', 'clone', 'close', 'closewoven', 'cloth', 'clothing', 'clustered', 'cm', 'co2', 'coast', 'coastal', 'coastline', 'coated', 'coating', 'code', 'coefficient', 'coil', 'coincidence', 'coined', 'collapsed', 'collapsible', 'collar', 'collectively', 'college', 'colonnus', 'color', 'colored', 'colour', 'colouration', 'coloured', 'combination', 'combinationaverages', 'combine', 'combined', 'come', 'comedy', 'commentator', 'commercial', 'commercially', 'common', 'commonly', 'commonwealth', 'community', 'company', 'comparatively', 'compensated', 'competition', 'competitive', 'competitor', 'complete', 'completely', 'complex', 'complexity', 'composed', 'composite', 'composition', 'comprehensive', 'comprise', 'compromised', 'computer', 'concealing', 'concentration', 'concept', 'concluded', 'conclusion', 'concord', 'concrete', 'concretethis', 'condition', 'conditioned', 'conduct', 'cone', 'conelike', 'configuration', 'conifer', 'coniferae', 'coniferales', 'coniferany', 'coniferophyta', 'coniferous', 'connects', 'conrad', 'conscious', 'conservative', 'considerable', 'consideration', 'considered', 'consisting', 'construction', 'consultancy', 'consumer', 'consumption', 'contagious', 'contain', 'contained', 'contains', 'contemporary', 'content', 'contest', 'continental', 'continue', 'contract', 'contractor', 'contributing', 'control', 'conversion', 'converted', 'cook', 'cooked', 'cooled', 'cooling', 'copy', 'coral', 'cordaites', 'corn', 'corner', 'cost', 'costing', 'cotton', 'coughed', 'coughing', 'could', 'counterpart', 'counting', 'country', 'couple', 'course', 'cover', 'covered', 'covering', 'crater', 'create', 'created', 'creates', 'creating', 'credential', 'credited', 'crevice', 'crisp', 'crispy', 'crossing', 'crust', 'crustacean', 'crustal', 'crystal', 'ct', 'ctdi', 'cu', 'cubic', 'cuff', 'culture', 'cupressaceae', 'current', 'customer', 'cypress', 'dacite', 'dakota', 'damaging', 'damsel', 'damselfish', 'dark', 'dartmouth', 'dascyllus', 'data', 'datadriven', 'date', 'daughter', 'day', 'daysydney', 'debut', 'deciduous', 'decisionmaking', 'decrease', 'dedelak', 'deep', 'defeating', 'defected', 'defend', 'defined', 'definition', 'degree', 'delfin', 'deliver', 'delivered', 'delivery', 'demand', 'democrat', 'democratic', 'demolition', 'department', 'depend', 'dependent', 'depending', 'depletion', 'deposit', 'derangement', 'derived', 'describe', 'described', 'describes', 'description', 'desert', 'deserted', 'design', 'designed', 'desired', 'despite', 'destination', 'detail', 'develop', 'development', 'device', 'devil', 'dextrose', 'dialogue', 'diarrhea', 'diet', 'difference', 'different', 'difficulty', 'digital', 'dionysia', 'dioxide', 'diplod', 'diploid', 'direct', 'direction', 'disambiguation', 'disc', 'disciplined', 'discussed', 'disease', 'dish', 'disillusioned', 'disney', 'disorder', 'disruption', 'dissected', 'dissolved', 'distinctive', 'distributor', 'district', 'disturbance', 'diver', 'divide', 'divided', 'division', 'divisionlevel', 'dlp', 'doctor', 'doesnt', 'dollar', 'dome', 'domestic', 'domestically', 'donald', 'doom', 'dorsal', 'dose', 'doubt', 'douglasfirs', 'dozen', 'dr', 'drama', 'dramatic', 'drawing', 'drew', 'drizzle', 'drop', 'dropped', 'drumstick', 'drysuit', 'duck', 'due', 'dump', 'durability', 'duration', 'dwrcoated', 'e', 'earlier', 'earliest', 'early', 'earth', 'easiest', 'easily', 'east', 'eastern', 'easy', 'easytounderstand', 'economic', 'editor', 'edward', 'effect', 'effective', 'egg', 'either', 'ejected', 'election', 'electoral', 'electra', 'electric', 'electrical', 'electronics', 'element', 'elementary', 'eliminate', 'eliquid', 'elsewhere', 'emblem', 'employ', 'employee', 'enabling', 'enameled', 'encompassed', 'encyclopedia', 'end', 'energy', 'engineering', 'england', 'enhance', 'enhanced', 'enhancement', 'enjoyed', 'enormous', 'enough', 'enter', 'enters', 'entity', 'entrepreneur', 'environment', 'equipment', 'eruption', 'eruptive', 'erupts', 'especially', 'essay', 'essential', 'establish', 'estimate', 'estimated', 'estimator', 'etc', 'euripedes', 'euripides', 'evaluate', 'evaluation', 'even', 'evenly', 'event', 'eventually', 'ever', 'evergreen', 'every', 'everyone', 'everywhere', 'exact', 'examine', 'examined', 'examiner', 'example', 'excavation', 'except', 'exceptional', 'excess', 'excessive', 'exchange', 'existing', 'exists', 'exotic', 'expect', 'expensive', 'experience', 'explained', 'explains', 'explore', 'exploring', 'explosive', 'exposed', 'extant', 'extending', 'extensive', 'external', 'extra', 'extremely', 'f', 'fabric', 'factitious', 'factor', 'fahrenheit', 'failure', 'fainting', 'fair', 'fairly', 'fall', 'fame', 'familiar', 'family', 'famous', 'fanning', 'fare', 'farm', 'fashion', 'fatty', 'faucetsaverage', 'favorite', 'favourite', 'feature', 'featured', 'featuring', 'february', 'fee', 'feed', 'feel', 'feeling', 'feisty', 'felt', 'female', 'ferraro', 'fertile', 'festival', 'fetussee', 'fever', 'fiber', 'fifth', 'fig', 'figure', 'file', 'filed', 'filing', 'filipino', 'fill', 'filled', 'film', 'fin', 'final', 'finally', 'financial', 'find', 'fine', 'finished', 'fir', 'fired', 'first', 'firsttime', 'fish', 'fishplant', 'fishthe', 'fishthese', 'fishwith', 'five', 'flat', 'fleece', 'flood', 'floor', 'flow', 'focus', 'focused', 'focusing', 'following', 'food', 'foot', 'footage', 'forced', 'ford', 'foreign', 'form', 'formally', 'formation', 'formed', 'former', 'forming', 'fossil', 'foul', 'found', 'foundation', 'four', 'framework', 'framing', 'francis', 'free', 'fresh', 'frog', 'front', 'fruit', 'fry', 'fuel', 'full', 'fulltime', 'fully', 'function', 'fundamentally', 'furnace', 'future', 'gallon', 'gamete', 'gametogenesis', 'garlic', 'garment', 'gas', 'gastrointestinal', 'gave', 'gear', 'geisel', 'general', 'generally', 'generously', 'genesis', 'genny', 'genre', 'genus', 'geographical', 'gerald', 'geraldine', 'germ', 'german', 'get', 'getaway', 'getting', 'giant', 'give', 'given', 'giving', 'gland', 'global', 'glucose', 'glycolysis', 'go', 'going', 'gold', 'golden', 'good', 'goretex', 'got', 'government', 'governor', 'grade', 'granite', 'granitic', 'grass', 'gravel', 'gray', 'great', 'greater', 'greatest', 'greece', 'greek', 'green', 'greenleaf', 'grew', 'grinch', 'gritty', 'group', 'grow', 'growth', 'gymnosperm', 'gymnospermous', 'ha', 'habit', 'half', 'halved', 'ham', 'hamilton', 'hampshire', 'haploid', 'harbour', 'hardened', 'hardscaping', 'hardy', 'harry', 'hat', 'havent', 'hawkesbury', 'haze', 'hco', 'heading', 'headquarters', 'health', 'hear', 'hears', 'heart', 'heat', 'heated', 'heating', 'heavy', 'hegeler', 'helen', 'help', 'hemlock', 'hermit', 'herniation', 'hero', 'hide', 'hiding', 'high', 'higher', 'higherend', 'highly', 'highvisibility', 'hire', 'hired', 'history', 'hold', 'hollywood', 'home', 'homebush', 'homeowner', 'homewyse', 'homologous', 'hood', 'hornfels', 'horton', 'hot', 'hour', 'hourly', 'house', 'household', 'however', 'httpwwwnationalparksnswgovauscheyvillenationalparkmigrantheritagewalkwalking', 'hub', 'human', 'humbug', 'hydrogen', 'hydronic', 'hyperventilation', 'icon', 'iconic', 'ideal', 'identification', 'identity', 'ie', 'igneous', 'ill', 'illinois', 'illustrated', 'illustrator', 'image', 'imaginative', 'imbalance', 'imitated', 'imitation', 'impact', 'impaired', 'importance', 'important', 'importantly', 'impregnated', 'impression', 'improve', 'improvement', 'improves', 'inapparent', 'inaugurated', 'inbox', 'inch', 'include', 'included', 'includes', 'including', 'increase', 'increased', 'increment', 'incubation', 'indeed', 'index', 'indicate', 'indirect', 'individual', 'indopacific', 'industrial', 'industry', 'inexpensive', 'infected', 'infection', 'inflammation', 'influential', 'information', 'inhabit', 'inhale', 'inhaled', 'initial', 'initiate', 'initiated', 'injected', 'inner', 'innerwest', 'innovation', 'inside', 'inspection', 'inspiration', 'install', 'installation', 'installed', 'instance', 'instant', 'instantly', 'instead', 'insufficient', 'insulate', 'insulation', 'insulin', 'intended', 'intentional', 'interestingly', 'interlocking', 'internal', 'international', 'interstitium', 'intervening', 'intricacy', 'intrigue', 'introduced', 'introducing', 'invention', 'inventor', 'invertebrate', 'involve', 'involved', 'involves', 'ion', 'iridescent', 'island', 'issue', 'issuing', 'itinerary', 'ive', 'jacket', 'january', 'jimmy', 'job', 'john', 'journal', 'jump', 'june', 'juniper', 'k', 'kanthal', 'kauri', 'keen', 'keep', 'kelly', 'kept', 'ketone', 'kid', 'kidney', 'kilauea', 'kind', 'king', 'kingdom', 'km', 'km²', 'know', 'knowledge', 'known', 'kolōnos', 'krakatoa', 'kwh', 'kōˈnifə', 'kōˈnifərəs', 'kə', 'l', 'labor', 'lack', 'lactic', 'land', 'landscaping', 'landslide', 'lapilli', 'larch', 'larchany', 'large', 'larger', 'largest', 'larix', 'late', 'later', 'latest', 'latin', 'latter', 'lava', 'layer', 'le', 'leader', 'leadership', 'leaf', 'learning', 'least', 'leaving', 'led', 'left', 'leg', 'lends', 'length', 'lesieg', 'lesson', 'let', 'letter', 'level', 'levy', 'liberal', 'lie', 'life', 'lifethreatening', 'ligament', 'lightcolored', 'lightfan', 'lightly', 'lightweight', 'like', 'likelihood', 'limestone', 'limited', 'line', 'lined', 'linen', 'linseed', 'liquid', 'list', 'listed', 'listen', 'listing', 'literacy', 'literature', 'little', 'live', 'liver', 'llc', 'load', 'lobe', 'local', 'locality', 'located', 'location', 'logo', 'long', 'longer', 'look', 'lorax', 'los', 'loss', 'lost', 'lot', 'low', 'lowend', 'lower', 'lucrative', 'lung', 'luxurious', 'luzon', 'lyric', 'mac', 'macdonald', 'macintosh', 'macintosha', 'mack', 'mackintosh', 'made', 'magma', 'main', 'mainly', 'maintain', 'maintaining', 'major', 'majority', 'make', 'makeup', 'malaise', 'male', 'malingering', 'mammal', 'man', 'management', 'manager', 'mangrove', 'manly', 'mantle', 'many', 'mapabout', 'marble', 'march', 'marine', 'mark', 'market', 'mascot', 'massachusetts', 'match', 'mate', 'material', 'matter', 'may', 'mean', 'measles', 'measured', 'meat', 'mechanical', 'medea', 'medeia', 'medical', 'medicine', 'mediumsized', 'meet', 'meiosi', 'meiosis', 'member', 'membrane', 'memorable', 'mental', 'mesh', 'metabolic', 'metabolism', 'metabolismthe', 'metal', 'metered', 'method', 'metro', 'metropolitan', 'mi', 'microscopic', 'microsoft', 'might', 'mike', 'mild', 'mile', 'million', 'mineral', 'minimum', 'minute', 'mischievous', 'mitosis', 'mix', 'mixed', 'mi²', 'mod', 'moderately', 'modern', 'modifier', 'molecule', 'mondale', 'monist', 'monosaccharide', 'month', 'moral', 'morsel', 'mostly', 'mount', 'mountain', 'movement', 'movie', 'much', 'mucus', 'mudstone', 'mulberry', 'multicellular', 'multiple', 'multiply', 'mum', 'mumps', 'muscle', 'muscular', 'museum', 'myers', 'mythical', 'mythological', 'n', 'name', 'named', 'nap', 'national', 'natural', 'naturally', 'nature', 'near', 'nearby', 'nearly', 'nebraska', 'necessary', 'neck', 'need', 'needle', 'needlelike', 'needleshaped', 'neighborhood', 'nervous', 'net', 'netiq', 'neurologic', 'neutral', 'neutralize', 'never', 'new', 'newest', 'newspaper', 'newswire', 'newtown', 'next', 'nichrome', 'nickel', 'nineteen', 'ningaloo', 'nixon', 'noah', 'non', 'nonrectangular', 'nonurban', 'normal', 'normally', 'north', 'northern', 'northerner', 'northnortheast', 'nose', 'notch', 'note', 'noted', 'noteprinting', 'noun', 'november', 'npa', 'number', 'numerous', 'nylon', 'objective', 'occasionally', 'occupation', 'occur', 'occurs', 'ocean', 'oceanic', 'oedipus', 'office', 'official', 'officially', 'offset', 'often', 'oil', 'oilcloth', 'oilies', 'oilskin', 'oilskina', 'old', 'older', 'oldest', 'olive', 'olympic', 'one', 'online', 'opera', 'opportunity', 'option', 'orangetail', 'order', 'organ', 'organism', 'organization', 'origin', 'original', 'others', 'otherwise', 'outback', 'outbreak', 'outer', 'outside', 'outstanding', 'oven', 'overabundance', 'overall', 'overboard', 'overproduction', 'overseas', 'overwhelmingly', 'ovum', 'oxford', 'oxygen', 'oxygenrich', 'ozone', 'pacific', 'pad', 'padspricing', 'page', 'pain', 'painti', 'pair', 'pale', 'paleozoic', 'palmfringed', 'pampanga', 'pan', 'pantomime', 'paralysis', 'parent', 'park', 'parkland', 'parramatta', 'part', 'partially', 'particular', 'particulate', 'partly', 'partner', 'party', 'pas', 'pass', 'past', 'patent', 'path', 'pathologic', 'patient', 'pattern', 'pay', 'paying', 'peaceful', 'pebble', 'pectoral', 'pelvic', 'pen', 'pennsylvanian', 'people', 'pepper', 'per', 'perfect', 'performance', 'performed', 'perhaps', 'period', 'permit', 'person', 'personal', 'pet', 'ph', 'philippine', 'phrase', 'physical', 'piece', 'pigment', 'pile', 'pillow', 'pinatubo', 'pine', 'pinea', 'pink', 'pinophyta', 'place', 'placing', 'plan', 'plankton', 'planning', 'plant', 'plantae', 'plasma', 'plastic', 'plate', 'plateau', 'play', 'playwright', 'pleasant', 'plenty', 'pleura', 'pleurisy', 'pleuritis', 'plural', 'plus', 'pneumonia', 'pocket', 'podocarpaceae', 'poet', 'point', 'polished', 'political', 'politician', 'pollen', 'pollination', 'pomacentridae', 'poor', 'popular', 'population', 'porous', 'portion', 'possible', 'possibly', 'postal', 'postfiling', 'potassium', 'potential', 'pour', 'poured', 'pouring', 'powder', 'power', 'powered', 'powerful', 'pox', 'pr', 'precursor', 'preexisting', 'prefers', 'preheat', 'preliminary', 'premiere', 'premnas', 'prepare', 'prepared', 'presence', 'present', 'presentation', 'presented', 'presidency', 'president', 'presidential', 'preston', 'prevent', 'price', 'pricing', 'pride', 'primarily', 'primary', 'princess', 'pro', 'probably', 'problem', 'process', 'produce', 'produced', 'product', 'production', 'professionally', 'program', 'progressive', 'project', 'prolonged', 'prominent', 'promoted', 'propane', 'properly', 'property', 'proprietary', 'prosecuting', 'prosecution', 'protect', 'protected', 'protective', 'protocolindependent', 'proven', 'provide', 'provided', 'providing', 'province', 'provisional', 'pseudonym', 'psychological', 'publication', 'published', 'pugnacious', 'pull', 'pulmonary', 'pumice', 'pump', 'pumped', 'pumping', 'purchase', 'purchased', 'purely', 'purpose', 'put', 'pyroclastic', 'q', 'qualified', 'quality', 'quantity', 'quarter', 'quartize', 'quartz', 'queensland', 'question', 'quick', 'quickdrying', 'quickly', 'quite', 'quote', 'r30', 'radiant', 'radiation', 'radio', 'radiocarbon', 'raincoat', 'rainhat', 'raise', 'raised', 'ran', 'random', 'randomly', 'range', 'rare', 'rarely', 'rash', 'rate', 'rather', 'rating', 'rationalizing', 'rba', 'rbas', 'reached', 'read', 'reading', 'ready', 'reagan', 'realism', 'rearing', 'reason', 'rebar', 'rebuildable', 'received', 'recent', 'recognizable', 'recognized', 'recommended', 'record', 'recording', 'red', 'reduced', 'reduces', 'redwood', 'reef', 'reelected', 'reelection', 'refer', 'reference', 'referred', 'referring', 'refers', 'refinish', 'reflects', 'regard', 'region', 'regional', 'register', 'regrading', 'reinforcement', 'related', 'relation', 'relevance', 'relict', 'remaining', 'remodel', 'removal', 'remove', 'removed', 'renal', 'renowned', 'repose', 'represented', 'reproduction', 'reproductive', 'republican', 'reputation', 'require', 'required', 'requirement', 'resemble', 'resembling', 'reserve', 'reserved', 'resident', 'resilient', 'resin', 'resistance', 'resort', 'respiratory', 'response', 'rest', 'restaurant', 'restricted', 'result', 'resulting', 'resultsbased', 'resumption', 'retention', 'return', 'returning', 'reveal', 'rewarded', 'rex', 'rhyme', 'rhyolite', 'rias', 'rib', 'ribcage', 'richard', 'richly', 'rid', 'ridge', 'right', 'rim', 'rise', 'risen', 'risk', 'riskbased', 'river', 'robert', 'rock', 'rockwork', 'roll', 'roman', 'ronald', 'rondeau', 'root', 'rosetta', 'roughly', 'route', 'rubberized', 'rubella', 'rule', 'run', 'running', 'safe', 'said', 'sailor', 'saint', 'sally', 'salt', 'saltwater', 'sand', 'sandstone', 'sapphire', 'satyr', 'sauce', 'saw', 'say', 'scale', 'scalelike', 'scandal', 'school', 'scientifically', 'scoria', 'scuba', 'sea', 'seal', 'sealed', 'second', 'secondary', 'secret', 'secretion', 'secure', 'securency', 'securitisations', 'see', 'seed', 'seedbearing', 'seen', 'seizure', 'select', 'semitropical', 'sense', 'sent', 'separate', 'separated', 'separating', 'sepsis', 'september', 'series', 'serious', 'serum', 'servant', 'served', 'service', 'session', 'set', 'setting', 'setup', 'seuss', 'seusss', 'seven', 'several', 'sex', 'sexual', 'shale', 'shallow', 'shape', 'sharing', 'sheeting', 'shoal', 'short', 'shot', 'show', 'shower', 'showeraverage', 'shown', 'shrub', 'side', 'sight', 'sign', 'silica', 'silicate', 'silicon', 'similar', 'simple', 'simpler', 'simply', 'since', 'single', 'sink', 'site', 'sits', 'six', 'size', 'skin', 'slab', 'slate', 'sleeve', 'slicker', 'slight', 'slightly', 'slow', 'small', 'smaller', 'smallest', 'smalltown', 'smell', 'smooth', 'snail', 'sneezed', 'sneezing', 'snout', 'soaked', 'software', 'sold', 'solution', 'solve', 'solvent', 'somatic', 'somatoform', 'someone', 'something', 'sometimes', 'soon', 'sophocles', 'sounding', 'source', 'south', 'southeast', 'souwester', 'soy', 'space', 'special', 'specialist', 'specie', 'specific', 'specimen', 'spell', 'spencer', 'spend', 'spending', 'spent', 'sperm', 'spine', 'split', 'spongy', 'spore', 'sport', 'spot', 'sprain', 'spray', 'spread', 'spreading', 'spring', 'springfield', 'sprinkle', 'spruce', 'square', 'st', 'stage', 'stamper', 'standard', 'star', 'start', 'starting', 'starvation', 'state', 'station', 'statistical', 'stats', 'steepsided', 'step', 'stethoscope', 'stick', 'sticky', 'still', 'stillpopular', 'stoic', 'stole', 'stomach', 'stone', 'storage', 'stored', 'story', 'strain', 'strategy', 'strato', 'stratosphere', 'stratovolcano', 'stratovolcanoes', 'street', 'strengthening', 'stressful', 'stretch', 'striking', 'stringency', 'stripe', 'striped', 'strong', 'structure', 'student', 'study', 'stunningly', 'stupid', 'stylish', 'subclinical', 'subduction', 'subject', 'submergent', 'subsidiary', 'substantial', 'substantially', 'substitute', 'subtypes', 'suburb', 'success', 'successful', 'suddenly', 'sugar', 'suggest', 'sulfuric', 'sulphur', 'super', 'supply', 'support', 'supported', 'surface', 'surprisingly', 'surround', 'survived', 'surviving', 'suːs', 'swathe', 'swimming', 'switched', 'swollen', 'sydney', 'symptom', 'synthetic', 'syrup', 'system', 'table', 'tail', 'take', 'taking', 'talk', 'talking', 'tall', 'tank', 'tar', 'tarlac', 'tasty', 'taxi', 'taxon', 'tayawan', 'teach', 'team', 'teaspoon', 'technology', 'telophase', 'temperature', 'temporarily', 'tendon', 'term', 'territorial', 'territory', 'test', 'tetrapod', 'text', 'textile', 'texture', 'thai', 'thats', 'theatre', 'theme', 'theo', 'theodor', 'therapy', 'there', 'thermometer', 'theyre', 'thick', 'thighsleg', 'thin', 'thing', 'think', 'thinking', 'third', 'thorax', 'though', 'thousand', 'three', 'threestriped', 'thriving', 'thro', 'throat', 'throughout', 'tie', 'til', 'tile', 'time', 'timeless', 'timer', 'tissue', 'today', 'together', 'toilet', 'told', 'toll', 'ton', 'tonne', 'top', 'total', 'touch', 'touching', 'towards', 'town', 'trace', 'trachea', 'trachis', 'trade', 'traditional', 'traditionally', 'tragedian', 'tragediesincluding', 'tragedy', 'tragedygreek', 'train', 'trajectory', 'transactiondependent', 'translated', 'translucent', 'transport', 'trapping', 'trauma', 'treated', 'tree', 'tremor', 'triangular', 'trio', 'tripoint', 'tropical', 'trouser', 'troy', 'truck', 'true', 'truman', 'trusted', 'try', 'trying', 'tubular', 'turning', 'tv', 'twentieth', 'twentyfour', 'two', 'type', 'typical', 'typically', 'u', 'ultimate', 'ultimately', 'unable', 'uncovered', 'underexcretion', 'underground', 'underlying', 'understand', 'understanding', 'unit', 'united', 'university', 'unknown', 'unlike', 'unofficial', 'unpaired', 'unrelated', 'unusual', 'upandcoming', 'updat', 'update', 'upon', 'upper', 'urban', 'urine', 'us', 'use', 'used', 'useful', 'user', 'userdependent', 'usgs', 'using', 'usually', 'utilize', 'utilizes', 'v', 'vaccination', 'vaccine', 'valley', 'value', 'vanity', 'vape', 'vaporizer', 'vaporizes', 'variance', 'variation', 'varicella', 'varies', 'variety', 'various', 'vary', 'varying', 'vast', 'vein', 'vendor', 'vent', 'ventricle', 'versa', 'vertebrate', 'vessel', 'vest', 'vice', 'vicepresidential', 'videodurationmomentjs', 'view', 'vigorously', 'viridiplantae', 'virus', 'visibility', 'visit', 'visitor', 'vividly', 'vol', 'volcanic', 'volcano', 'volume', 'vomiting', 'voter', 'votesthe', 'w', 'waistline', 'wale', 'walk', 'walking', 'wall', 'wallsfiberglass', 'walter', 'want', 'wanted', 'war', 'warm', 'water', 'waterproof', 'waterproofers', 'way', 'waystep', 'weakness', 'wear', 'wearer', 'wearing', 'weather', 'webmd', 'week', 'well', 'wellbeing', 'wellknown', 'west', 'western', 'wet', 'whereas', 'whether', 'white', 'whitestriped', 'whitetailed', 'whitsunday', 'whole', 'wick', 'wide', 'widely', 'widespread', 'width', 'wikipedia', 'wilson', 'win', 'wind', 'windpipe', 'wire', 'witched', 'within', 'woman', 'woody', 'work', 'worker', 'working', 'workingclass', 'world', 'worldwide', 'worn', 'woronora', 'worst', 'worth', 'worthy', 'would', 'woven', 'wrist', 'write', 'writer', 'writing', 'written', 'wrote', 'x', 'xenolith', 'yard', 'year', 'yellow', 'yellowtail', 'yes', 'yet', 'yew', 'york', 'youll', 'young', 'younger', 'youre', 'youth', 'youve', 'zambales', 'zip', 'zone', 'zoned', 'zoo', 'zygote', 'ˈreɪɡən', 'ˈrɒnəld', 'ˈsɔɪs', 'ˈwɪlsən', 'ˈɡaɪzəl']\n"
     ]
    }
   ],
   "source": [
    "len_all_tokens = len(unique_tokens_in_all)\n",
    "sorted_tokens = sorted(unique_tokens_in_all)\n",
    "\n",
    "print(len_all_tokens)\n",
    "print(sorted_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________________\n",
    "## tfidf matrix for words\n",
    "تف_ایدف هر کلمه رو داخل داکیومنت ش ذخیره کرده\n",
    "یعنی هر کلمه توی فلان داکیومنت چقدر مهمه"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Abdelahi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Abdelahi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "100%|██████████| 50001/50001 [14:31:51<00:00,  1.05s/it]        \n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 84.7 GiB for an array with shape (50001, 227427) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[423], line 52\u001b[0m\n\u001b[0;32m     49\u001b[0m         data_list\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFilename\u001b[39m\u001b[38;5;124m'\u001b[39m: filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContent\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(tokens)})\n\u001b[0;32m     51\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data_list)\n\u001b[1;32m---> 52\u001b[0m tfidf_df_words \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_tfidf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mContent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m tfidf_df_words\n",
      "Cell \u001b[1;32mIn[423], line 35\u001b[0m, in \u001b[0;36mcalculate_tfidf\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     33\u001b[0m tfidf_matrix \u001b[38;5;241m=\u001b[39m vectorizer\u001b[38;5;241m.\u001b[39mfit_transform(data)\n\u001b[0;32m     34\u001b[0m feature_names \u001b[38;5;241m=\u001b[39m vectorizer\u001b[38;5;241m.\u001b[39mget_feature_names_out()\n\u001b[1;32m---> 35\u001b[0m tfidf_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mtfidf_matrix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, columns\u001b[38;5;241m=\u001b[39mfeature_names)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tfidf_df\n",
      "File \u001b[1;32mc:\\Users\\Abdelahi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\sparse\\_compressed.py:1051\u001b[0m, in \u001b[0;36m_cs_matrix.toarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m order \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1050\u001b[0m     order \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_swap(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcf\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m-> 1051\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_toarray_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1052\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (out\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mc_contiguous \u001b[38;5;129;01mor\u001b[39;00m out\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mf_contiguous):\n\u001b[0;32m   1053\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOutput array must be C or F contiguous\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Abdelahi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\sparse\\_base.py:1298\u001b[0m, in \u001b[0;36mspmatrix._process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[0;32m   1297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39morder)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 84.7 GiB for an array with shape (50001, 227427) and data type float64"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def tokenize_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    return tokens\n",
    "\n",
    "def preprocess_text(text):\n",
    "    tokens = tokenize_text(text)\n",
    "    tokens = lowercase(tokens)\n",
    "    tokens = remove_stopwords(tokens)\n",
    "    return tokens\n",
    "\n",
    "def lowercase(tokens):\n",
    "    lowercase_tokens = [token.lower() for token in tokens]\n",
    "    return lowercase_tokens\n",
    "\n",
    "def remove_stopwords(tokens):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    return filtered_tokens\n",
    "\n",
    "def calculate_tfidf(data):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(data)\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=feature_names)\n",
    "    return tfidf_df\n",
    "\n",
    "data_folder = 'data'\n",
    "data_list = []\n",
    "\n",
    "for filename in tqdm(os.listdir(data_folder)):\n",
    "    if filename.endswith('.txt'):\n",
    "        file_path = os.path.join(data_folder, filename)\n",
    "\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "        \n",
    "        tokens = preprocess_text(content)\n",
    "        data_list.append({'Filename': filename, 'Content': ' '.join(tokens)})\n",
    "\n",
    "df = pd.DataFrame(data_list)\n",
    "tfidf_df_words = calculate_tfidf(df['Content'])\n",
    "\n",
    "tfidf_df_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "نکته:\n",
    "کلمات این ماتریس یونیک اند\n",
    "درضمن اگه کلمه ای رو میخوای توش پیدا کنی باید لوورکیس و بن و غیز اسم استاپ ورد.. شده باشه"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06906484693653837"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#برای چک کردن درستی ماتریس\n",
    "tfidf_df_words['2007']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tokenizing documents to sentences then tfidf for sentenes\n",
    "پیدا کردن جملات هر داکیومنت و تبدیلشون به وکتورهایی از ایندکس های ماتریس تفایدف"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>document_0.txt</td>\n",
       "      <td>Since 2007, the RBA's outstanding reputation h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>document_0.txt</td>\n",
       "      <td>These RBA subsidiaries were involved in bribin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>document_0.txt</td>\n",
       "      <td>The assets of the bank include the gold and fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>document_0.txt</td>\n",
       "      <td>Nearly 94% of the RBA's employees work at its ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>document_0.txt</td>\n",
       "      <td>The Reserve Bank of Australia (RBA) came into ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>document_19.txt</td>\n",
       "      <td>A patient is contagious in the week before the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>document_19.txt</td>\n",
       "      <td>The virus is spread when you inhale or touch s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>document_19.txt</td>\n",
       "      <td>For most patients, vaccination is a safe and e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>document_19.txt</td>\n",
       "      <td>The German measles vaccine is typically combin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>document_19.txt</td>\n",
       "      <td>These shots are usually given between 12 and 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>729 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            filename                                           sentence\n",
       "0     document_0.txt  Since 2007, the RBA's outstanding reputation h...\n",
       "1     document_0.txt  These RBA subsidiaries were involved in bribin...\n",
       "2     document_0.txt  The assets of the bank include the gold and fo...\n",
       "3     document_0.txt  Nearly 94% of the RBA's employees work at its ...\n",
       "4     document_0.txt  The Reserve Bank of Australia (RBA) came into ...\n",
       "..               ...                                                ...\n",
       "724  document_19.txt  A patient is contagious in the week before the...\n",
       "725  document_19.txt  The virus is spread when you inhale or touch s...\n",
       "726  document_19.txt  For most patients, vaccination is a safe and e...\n",
       "727  document_19.txt  The German measles vaccine is typically combin...\n",
       "728  document_19.txt  These shots are usually given between 12 and 1...\n",
       "\n",
       "[729 rows x 2 columns]"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import nltk\n",
    "\n",
    "sentence_list = []\n",
    "max_docs = 20\n",
    "docs_read = 0\n",
    "\n",
    "for i in range(max_docs):\n",
    "    filename = f\"document_{i}.txt\"\n",
    "    file_path = os.path.join(data_folder, filename)\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    # Tokenize the content into sentences\n",
    "    sentences = nltk.sent_tokenize(content)\n",
    "\n",
    "    # Append each sentence to the list with a unique label\n",
    "    for sentence in sentences:\n",
    "        sentence_list.append({'filename': filename, 'sentence': sentence})\n",
    "\n",
    "    docs_read += 1\n",
    "\n",
    "# Convert sentence_list to a DataFrame\n",
    "df_sentences = pd.DataFrame(sentence_list)\n",
    "\n",
    "# Print the DataFrame\n",
    "df_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>sentence</th>\n",
       "      <th>uniqe_tokens_in_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>document_0.txt</td>\n",
       "      <td>Since 2007, the RBA's outstanding reputation h...</td>\n",
       "      <td>[securency, scandal, npa, 2007, outstanding, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>document_0.txt</td>\n",
       "      <td>These RBA subsidiaries were involved in bribin...</td>\n",
       "      <td>[noteprinting, contract, lucrative, subsidiary...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>document_0.txt</td>\n",
       "      <td>The assets of the bank include the gold and fo...</td>\n",
       "      <td>[foreign, worth, estimated, australia, exchang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>document_0.txt</td>\n",
       "      <td>Nearly 94% of the RBA's employees work at its ...</td>\n",
       "      <td>[employee, work, south, resumption, headquarte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>document_0.txt</td>\n",
       "      <td>The Reserve Bank of Australia (RBA) came into ...</td>\n",
       "      <td>[1960, act, 1959, removed, central, australia,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>document_19.txt</td>\n",
       "      <td>A patient is contagious in the week before the...</td>\n",
       "      <td>[week, outbreak, patient, two, rash, contagiou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>document_19.txt</td>\n",
       "      <td>The virus is spread when you inhale or touch s...</td>\n",
       "      <td>[secretion, virus, person, inhale, touch, infe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>document_19.txt</td>\n",
       "      <td>For most patients, vaccination is a safe and e...</td>\n",
       "      <td>[effective, safe, prevent, patient, german, me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>document_19.txt</td>\n",
       "      <td>The German measles vaccine is typically combin...</td>\n",
       "      <td>[well, mumps, typically, pox, virus, cause, va...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>document_19.txt</td>\n",
       "      <td>These shots are usually given between 12 and 1...</td>\n",
       "      <td>[month, 15, age, given, usually, shot, 12]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>729 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            filename                                           sentence  \\\n",
       "0     document_0.txt  Since 2007, the RBA's outstanding reputation h...   \n",
       "1     document_0.txt  These RBA subsidiaries were involved in bribin...   \n",
       "2     document_0.txt  The assets of the bank include the gold and fo...   \n",
       "3     document_0.txt  Nearly 94% of the RBA's employees work at its ...   \n",
       "4     document_0.txt  The Reserve Bank of Australia (RBA) came into ...   \n",
       "..               ...                                                ...   \n",
       "724  document_19.txt  A patient is contagious in the week before the...   \n",
       "725  document_19.txt  The virus is spread when you inhale or touch s...   \n",
       "726  document_19.txt  For most patients, vaccination is a safe and e...   \n",
       "727  document_19.txt  The German measles vaccine is typically combin...   \n",
       "728  document_19.txt  These shots are usually given between 12 and 1...   \n",
       "\n",
       "                              uniqe_tokens_in_sentence  \n",
       "0    [securency, scandal, npa, 2007, outstanding, a...  \n",
       "1    [noteprinting, contract, lucrative, subsidiary...  \n",
       "2    [foreign, worth, estimated, australia, exchang...  \n",
       "3    [employee, work, south, resumption, headquarte...  \n",
       "4    [1960, act, 1959, removed, central, australia,...  \n",
       "..                                                 ...  \n",
       "724  [week, outbreak, patient, two, rash, contagiou...  \n",
       "725  [secretion, virus, person, inhale, touch, infe...  \n",
       "726  [effective, safe, prevent, patient, german, me...  \n",
       "727  [well, mumps, typically, pox, virus, cause, va...  \n",
       "728         [month, 15, age, given, usually, shot, 12]  \n",
       "\n",
       "[729 rows x 3 columns]"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Apply tokenization to each sentence in the DataFrame\n",
    "df_sentences[\"uniqe_tokens_in_sentence\"] = df_sentences[\"sentence\"].apply(tokenize_text)\n",
    "\n",
    "# Print the updated DataFrame\n",
    "df_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Create an empty list to store the sentence_tfidf vectors\n",
    "sentence_tfidf = []\n",
    "\n",
    "# Iterate through each row in the dataframe\n",
    "for index, row in df_sentences.iterrows():\n",
    "    filename = row['filename']\n",
    "    match = re.search(r'document_(\\d+)\\.txt', filename)\n",
    "    if match:\n",
    "        file_index = int(match.group(1))\n",
    "        tokens = row['uniqe_tokens_in_sentence']\n",
    "        tfidf_vector = [tfidf_df_words[token][file_index] if token in tfidf_df_words and token in tokens else 0 for token in sorted_tokens]\n",
    "        sentence_tfidf.append(tfidf_vector)\n",
    "\n",
    "# Add the sentence_tfidf column to the dataframe\n",
    "df_sentences['sentence_tfidf'] = sentence_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>sentence</th>\n",
       "      <th>uniqe_tokens_in_sentence</th>\n",
       "      <th>sentence_tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>document_0.txt</td>\n",
       "      <td>Since 2007, the RBA's outstanding reputation h...</td>\n",
       "      <td>securency scandal npa 2007 outstanding affecte...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>document_0.txt</td>\n",
       "      <td>These RBA subsidiaries were involved in bribin...</td>\n",
       "      <td>noteprinting contract lucrative subsidiary win...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>document_0.txt</td>\n",
       "      <td>The assets of the bank include the gold and fo...</td>\n",
       "      <td>foreign worth estimated australia exchange res...</td>\n",
       "      <td>[0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>document_0.txt</td>\n",
       "      <td>Nearly 94% of the RBA's employees work at its ...</td>\n",
       "      <td>employee work south resumption headquarters bu...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>document_0.txt</td>\n",
       "      <td>The Reserve Bank of Australia (RBA) came into ...</td>\n",
       "      <td>1960 act 1959 removed central australia bankno...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>document_19.txt</td>\n",
       "      <td>A patient is contagious in the week before the...</td>\n",
       "      <td>week outbreak patient two rash contagious clear</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>document_19.txt</td>\n",
       "      <td>The virus is spread when you inhale or touch s...</td>\n",
       "      <td>secretion virus person inhale touch infected s...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>document_19.txt</td>\n",
       "      <td>For most patients, vaccination is a safe and e...</td>\n",
       "      <td>effective safe prevent patient german measles ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>document_19.txt</td>\n",
       "      <td>The German measles vaccine is typically combin...</td>\n",
       "      <td>well mumps typically pox virus cause varicella...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>document_19.txt</td>\n",
       "      <td>These shots are usually given between 12 and 1...</td>\n",
       "      <td>month 15 age given usually shot 12</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0756140297...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>729 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            filename                                           sentence  \\\n",
       "0     document_0.txt  Since 2007, the RBA's outstanding reputation h...   \n",
       "1     document_0.txt  These RBA subsidiaries were involved in bribin...   \n",
       "2     document_0.txt  The assets of the bank include the gold and fo...   \n",
       "3     document_0.txt  Nearly 94% of the RBA's employees work at its ...   \n",
       "4     document_0.txt  The Reserve Bank of Australia (RBA) came into ...   \n",
       "..               ...                                                ...   \n",
       "724  document_19.txt  A patient is contagious in the week before the...   \n",
       "725  document_19.txt  The virus is spread when you inhale or touch s...   \n",
       "726  document_19.txt  For most patients, vaccination is a safe and e...   \n",
       "727  document_19.txt  The German measles vaccine is typically combin...   \n",
       "728  document_19.txt  These shots are usually given between 12 and 1...   \n",
       "\n",
       "                              uniqe_tokens_in_sentence  \\\n",
       "0    securency scandal npa 2007 outstanding affecte...   \n",
       "1    noteprinting contract lucrative subsidiary win...   \n",
       "2    foreign worth estimated australia exchange res...   \n",
       "3    employee work south resumption headquarters bu...   \n",
       "4    1960 act 1959 removed central australia bankno...   \n",
       "..                                                 ...   \n",
       "724    week outbreak patient two rash contagious clear   \n",
       "725  secretion virus person inhale touch infected s...   \n",
       "726  effective safe prevent patient german measles ...   \n",
       "727  well mumps typically pox virus cause varicella...   \n",
       "728                 month 15 age given usually shot 12   \n",
       "\n",
       "                                        sentence_tfidf  \n",
       "0    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2    [0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...  \n",
       "3    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "..                                                 ...  \n",
       "724  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "725  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "726  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "727  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "728  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0756140297...  \n",
       "\n",
       "[729 rows x 4 columns]"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "#یه مثال برای اینکه مطمئن شیم وکتوری تولید شده برای هر جمله درسته\n",
    "\n",
    "sorted_tokens = sorted(unique_tokens_in_all)\n",
    "vector = sentence_tfidf[0]  # وکتور جمله اول\n",
    "\n",
    "# ترکیب لیست sorted_tokens و بردار متناظر\n",
    "token_vector_tuples = zip(sorted_tokens, vector)\n",
    "\n",
    "# تبدیل تاپل به رشته و چاپ توکن‌ها با چند خط فاصله\n",
    "result_str = '\\n\\n'.join(f'{token}: {value}' for token, value in token_vector_tuples)\n",
    "\n",
    "# ذخیره رشته در یک فایل متنی\n",
    "# ذخیره رشته در یک فایل متنی با کدک UTF-8\n",
    "with open('sentence0ofdocument0.txt', 'w', encoding='utf-8') as file:\n",
    "    file.write(result_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tfidf for documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           filename                                      unique_tokens  \\\n",
      "0    document_0.txt  {netiq sense simple surface identity family im...   \n",
      "1    document_1.txt  {jimmy 1980 ford earlier republican malaise ye...   \n",
      "2   document_10.txt  {chromosome parent number diploid division mei...   \n",
      "3   document_11.txt  {ˈɡaɪzəl 1904 seuss pen september known 24 bes...   \n",
      "4   document_12.txt  {leg bake 375f chicken, 2 garlic sprinkle powd...   \n",
      "5   document_13.txt  {installed size expect floor radiant rate foot...   \n",
      "6   document_14.txt  {magma crust mantle earth used within liquid d...   \n",
      "7   document_15.txt  {cost estimate concrete pad instant install ge...   \n",
      "8   document_16.txt  {inhabit specie marine lower stretch water riv...   \n",
      "9   document_17.txt  {phrase los coined wanted first lost got, brai...   \n",
      "10  document_18.txt  {36 oilcloth piece purchase one 47 sent yard, ...   \n",
      "11  document_19.txt  {well mumps typically pox virus cause varicell...   \n",
      "12   document_2.txt  {great hamilton one popular island spot reef s...   \n",
      "13   document_3.txt  {cost lightfan floor hour ceiling per one foot...   \n",
      "14   document_4.txt  {disorder malingering patient importantly inte...   \n",
      "15   document_5.txt  {4 people useful found, reserved right, heart ...   \n",
      "16   document_6.txt  {detail devil always, 8000 15000, cost patent ...   \n",
      "17   document_7.txt  {ph tissue blood depletion acid ion reserve hy...   \n",
      "18   document_8.txt  {placing sophocles never play lower place twen...   \n",
      "19   document_9.txt  {tree cone shrub reproduction part conifer pro...   \n",
      "\n",
      "                                               vector  \n",
      "0   [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
      "1   [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2138318...  \n",
      "2   [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
      "3   [[0.20084103320076013, 0.0, 0.0, 0.0, 0.0, 0.0...  \n",
      "4   [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
      "5   [[0.0, 0.0, 0.0, 0.0, 0.21812256122068632, 0.0...  \n",
      "6   [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
      "7   [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
      "8   [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
      "9   [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
      "10  [[0.0, 0.0, 0.0, 0.3723403184932674, 0.3723403...  \n",
      "11  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
      "12  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
      "13  [[0.0, 0.0, 0.18855775923797582, 0.0, 0.0, 0.0...  \n",
      "14  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
      "15  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
      "16  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
      "17  [[0.0, 0.0, 0.30431004954198754, 0.15270865594...  \n",
      "18  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
      "19  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# ساخت یک نمونه از TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# تبدیل کلمات یونیک به بردارهای TF-IDF\n",
    "grouped_tokens[\"vector\"] = grouped_tokens[\"unique_tokens\"].apply(lambda x: vectorizer.fit_transform(x).toarray())\n",
    "\n",
    "# نمایش دیتافریم جدید\n",
    "print(grouped_tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
